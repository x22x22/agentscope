{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Prompt Formatting\n\nAgentScope supports developers to build prompt that fits different model APIs\nby providing a set of built-in strategies for both chat and multi-agent\nscenarios.\n\nSpecifically, AgentScope supports both model-specific and model-agnostic\nformatting.\n\n.. tip:: **Chat scenario** refers to the conversation between a user and an\n assistant, while **multi-agent scenario** involves multiple agents with\n different names (though their roles are all \"assistant\").\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Currently, most LLM API providers only support chat scenario. For</p></div>\n example, only two roles (user and assistant) are involved in the conversation\n and sometimes they must speak alternatively.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>There is no **one-size-fits-all** solution for prompt formatting.</p></div>\n The goal of built-in strategies is to **enable beginners to smoothly invoke\n the model API, rather than achieving the best performance**.\n For advanced users, we highly recommend developers to customize prompts\n according to their needs and model API requirements.\n\n## Model-Agnostic Formatting\n\nWhen you want your application to work with different model APIs\nsimultaneously, the model-agnostic formatting is a good idea.\n\nAgentScope achieves model-agnostic formatting by supporting to load the model\nfrom configuration, and presets a collection of built-in formatting strategies\nfor different model APIs and scenarios (chat or multi-agent) in the\nmodel wrapper class.\n\nYou can directly use the `format` method of the model object to format the\ninput messages without knowing the details of the model API. Taking DashScope\nChat API as an example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Union, Optional\n\nfrom agentscope.agents import AgentBase\nfrom agentscope.message import Msg\nfrom agentscope.manager import ModelManager\nimport agentscope\nimport json\n\n# Load the model configuration\nagentscope.init(\n    model_configs={\n        \"config_name\": \"my_qwen\",\n        \"model_type\": \"dashscope_chat\",\n        \"model_name\": \"qwen-max\",\n    },\n)\n\n# Get the model object from model manager\nmodel = ModelManager.get_instance().get_model_by_config_name(\"my_qwen\")\n\n# `Msg` objects or a list of `Msg` objects can be passed to the `format` method\nprompt = model.format(\n    Msg(\"system\", \"You're a helpful assistant.\", \"system\"),\n    [\n        Msg(\"assistant\", \"Hi!\", \"assistant\"),\n        Msg(\"user\", \"Nice to meet you!\", \"user\"),\n    ],\n    multi_agent_mode=False,\n)\n\nprint(json.dumps(prompt, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After formatting the input messages, we can input the prompt into the model\nobject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "response = model(prompt)\n\nprint(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also, you can use format the messages in the multi-agent scenario by\nsetting `multi_agent_mode=True`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prompt = model.format(\n    Msg(\"system\", \"You're a helpful assistant named Alice.\", \"system\"),\n    [\n        Msg(\"Alice\", \"Hi!\", \"assistant\"),\n        Msg(\"Bob\", \"Nice to meet you!\", \"assistant\"),\n    ],\n    multi_agent_mode=True,\n)\n\nprint(json.dumps(prompt, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Within the agent, the model-agnostic formatting is achieved as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyAgent(AgentBase):\n    def __init__(self, name: str, model_config_name: str, **kwargs) -> None:\n        super().__init__(name=name, model_config_name=model_config_name)\n\n        # ...\n\n    def reply(self, x: Optional[Union[Msg, list[Msg]]] = None) -> Msg:\n        # ...\n\n        # Format the messages without knowing the model API\n        prompt = self.model.format(\n            Msg(\"system\", \"{your system prompt}\", \"system\"),\n            self.memory.get_memory(),\n            multi_agent_mode=True,\n        )\n        response = self.model(prompt)\n\n        # ...\n        return Msg(self.name, response.text, role=\"assistant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip:: All the formatting strategies are implemented under\n`agentscope.formatter` module. The model wrapper decides which strategy to\nuse based on the model name.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model-Specific Formatting\n\nThe `agentscope.formatter` module implements the built-in formatting\nstrategies for different model APIs and scenarios. They provide\n`format_chat` and `format_multi_agent` methods, as well as a `format_auto`\nfunction that automatically selects the appropriate method based on the\ninput messages.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.formatters import OpenAIFormatter\n\nmulti_agent_messages = [\n    Msg(\"system\", \"You're a helpful assistant named Alice.\", \"system\"),\n    Msg(\"Alice\", \"Hi!\", \"assistant\"),\n    Msg(\"Bob\", \"Nice to meet you!\", \"assistant\"),\n    Msg(\"Charlie\", \"Nice to meet you, too!\", \"user\"),\n]\n\nchat_messages = [\n    Msg(\"system\", \"You're a helpful assistant named Alice.\", \"system\"),\n    Msg(\"Bob\", \"Nice to meet you!\", \"user\"),\n    Msg(\"Alice\", \"Hi! How can I help you?\", \"assistant\"),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multi-agent scenario:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "formatted_multi_agent = OpenAIFormatter.format_multi_agent(\n    multi_agent_messages,\n)\nprint(json.dumps(formatted_multi_agent, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chat scenario:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "formatted_chat = OpenAIFormatter.format_chat(\n    chat_messages,\n)\nprint(json.dumps(formatted_chat, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Auto formatting when only two entities are involved:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "formatted_auto_chat = OpenAIFormatter.format_auto(\n    chat_messages,\n)\nprint(json.dumps(formatted_auto_chat, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Auto formatting when more than two entities (multi-agent) are involved:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "formatted_auto_multi_agent = OpenAIFormatter.format_auto(\n    multi_agent_messages,\n)\nprint(json.dumps(formatted_auto_multi_agent, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The available formatter classes are:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.formatters import (\n    CommonFormatter,\n    AnthropicFormatter,\n    OpenAIFormatter,\n    GeminiFormatter,\n    DashScopeFormatter,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `CommonFormatter` is a basic formatter for common chat LLMs, such as\nZhipuAI API, Yi API, ollama, LiteLLM, etc.\n\n## Vision Models\n\nFor vision models, AgentScope currently supports OpenAI, DashScope and\nAnthropic vision models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.message import TextBlock, ImageBlock\n\n# we create a fake image locally\nwith open(\"./image.jpg\", \"w\") as f:\n    f.write(\"fake image\")\n\nmulti_modal_messages = [\n    Msg(\"system\", \"You're a helpful assistant named Alice.\", \"system\"),\n    Msg(\n        \"Alice\",\n        [\n            TextBlock(type=\"text\", text=\"Help me to describe the two images?\"),\n            ImageBlock(type=\"image\", url=\"https://example.com/image.jpg\"),\n            ImageBlock(type=\"image\", url=\"./image.jpg\"),\n        ],\n        \"user\",\n    ),\n    Msg(\"Bob\", \"Sure!\", \"assistant\"),\n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"OpenAI prompt:\")\nopenai_prompt = OpenAIFormatter.format_chat(multi_modal_messages)\nprint(json.dumps(openai_prompt, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nDashscope prompt:\")\ndashscope_prompt = DashScopeFormatter.format_chat(multi_modal_messages)\nprint(json.dumps(dashscope_prompt, indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nAnthropic prompt:\")\nanthropic_prompt = AnthropicFormatter.format_chat(multi_modal_messages)\nprint(json.dumps(anthropic_prompt, indent=4, ensure_ascii=False))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}