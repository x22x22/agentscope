{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Structured Output\n\nAgentScope supports two structured output methods, as shown in the following\nfigure:\n\n- Tool API: Construct a function with input parameters as the fields of the required structured data, and then ask the LLM to call the function to obtain the structured data.\n- Text Parsing: Call the LLM API to obtain plain text data, and then parse the structured data from the plain text locally.\n\n<img src=\"https://img.alicdn.com/imgextra/i4/O1CN01TLx5qg1tcmx3cKCNN_!!6000000005923-55-tps-661-391.svg\" width=\"100%\" alt=\"\u4e24\u79cd\u4e0d\u540c\u7684\u7ed3\u6784\u5316\u8f93\u51fa\u65b9\u5f0f\">\n\nThe advantages and disadvantages of the two methods are as follows:\n\n.. list-table::\n    :header-rows: 1\n\n    * - Method\n      - Advantages\n      - Disadvantages\n    * - Tool API\n      - 1. The model **autonomously** decides when to call the function/generate structured output, which can be well combined with the ReAct algorithm.\n        2. Data parsing occurs at the LLM API provider, making local development easier.\n        3. Supports complex constraints based on JSON Schema.\n      - Requires an LLM API that supports tool invocation.\n    * - Text Parsing\n      - 1. Simple and easy to use.\n        2. Can adjust the format and parsing method based on model capabilities and required structured data.\n      - 1. Relies on model capabilities, which may never produce structured data that meets the requirements.\n        2. The model **passively** generates structured data, and the developer decides when to prompt the LLM to generate structured data.\n\n\nNext we will introduce how AgentScope supports these two different parsing methods.\n\n## Tool API\n\nThe Tool API method combines tool invocation and structured output. For example, if we need the fields `\"thought\"`, `\"choice\"`, and `\"number\"`, we can construct a function as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Literal\nfrom pydantic import BaseModel, Field\nimport json\n\n\ndef generate_response(\n    thought: str,\n    choice: Literal[\"apple\", \"banana\"],\n    number: int,\n) -> None:\n    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function signature serves as a constraint, and when the model correctly\ninvokes the function, we can obtain the corresponding structured data.\n\nConsidering that some complex constraints cannot be expressed using Python's\ntype annotations, AgentScope supports defining complex constraints using\nPydantic's `BaseModel`\nTaking the following two models as an example:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class Model1(BaseModel):\n    name: str = Field(min_length=0, max_length=20, description=\"The name\")\n    description: str = Field(\n        min_length=0,\n        max_length=200,\n        description=\"The brief description\",\n    )\n    age: int = Field(ge=0, le=100, description=\"The age\")\n\n\nclass Model2(BaseModel):\n    choice: Literal[\"apple\", \"banana\"] = Field(description=\"Your choice\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ReActAgentV2` class in AgentScope will combine the JSON Schema of the\n`BaseModel` subclass with the schema of a function named `generate_response`.\nThis will generate a new schema that can be used to constrain the model's\noutput when calling the function.\n\nFor example, the following code demonstrates how to use `ReActAgentV2` to\ncombine the ReAct algorithm with structured output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.agents import ReActAgentV2\nfrom agentscope.service import ServiceToolkit\nfrom agentscope.message import Msg\nimport agentscope\n\nagentscope.init(\n    model_configs={\n        \"config_name\": \"my_config\",\n        \"model_type\": \"dashscope_chat\",\n        \"model_name\": \"qwen-max\",\n    },\n)\n\ntoolkit = ServiceToolkit()\n\nagent = ReActAgentV2(\n    name=\"Friday\",\n    model_config_name=\"my_config\",\n    service_toolkit=toolkit,\n)\n\nmsg1 = Msg(\"user\", \"Introduce Einstein\", \"user\")\nres_msg = agent(msg1, structured_model=Model1)\n\nprint(\"The structured output: \", res_msg.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With different `structured_model`, we can achieve different structured output\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "msg2 = Msg(\"user\", \"Pick a fruit\", \"user\")\nres_msg = agent(msg2, structured_model=Model2)\n\nprint(\"The structured output: \", res_msg.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To observe how `ReActAgentV2` dynamically constructs the schema of the\nfunction, we remove a hook function that cleans up the structured output,\nallowing us to print the processed function schema.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Clear the memory\nagent.memory.clear()\n# Remove the hook function that cleans up the structured output\nagent.remove_hook(\"post_reply\", \"as_clear_structured_output\")\n\n# Observe the current schema of the target function\nprint(\n    json.dumps(\n        toolkit.json_schemas[agent._finish_function],\n        indent=4,\n        ensure_ascii=False,\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we call the agent once and observe the changes in the schema of the target function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res_msg = agent(msg1, structured_model=Model1)\n\nprint(\n    json.dumps(\n        toolkit.json_schemas[agent._finish_function],\n        indent=4,\n        ensure_ascii=False,\n    ),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the schema of the `generate_response` function has been combined with the schema of the `Model1` class.\nTherefore, when the model calls this function, it will generate the corresponding structured data.\n\n.. tip:: More implementation details can be found in the `ReActAgentV2` [source code](https://github.com/modelscope/agentscope/blob/main/src/agentscope/agents/_react_agent_v2.py)\n\n## Text Parsing\n\nAgentScope's `parsers` module provides various parser classes that developers can choose from based on the required structured data.\n\nHere's an example of using `MarkdownJsonDictParser` to parse structured data from Markdown-formatted text.\n\n### Defining the Parser\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.models import ModelResponse\nfrom agentscope.parsers import MarkdownJsonDictParser\n\n\nparser = MarkdownJsonDictParser(\n    content_hint='{\"thought\": \"What you thought\", \"speak\": \"What you speak to the user\"}',\n    required_keys=[\"thought\", \"speak\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parser will generate a format instruction according to your input. You\ncan use the `format_instruction` property to in your prompt to guide LLM to\ngenerate the desired output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(parser.format_instruction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parsing the Output\nWhen receiving output from LLM, use `parse` method to extract the\nstructured data.\nIt takes an object of `agentscope.models.ModelResponse` as input, parses\nthe value of the `text` field, and returns a parsed dictionary in the\n`parsed` field.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dummy_response = ModelResponse(\n    text=\"\"\"```json\n{\n    \"thought\": \"I should greet the user\",\n    \"speak\": \"Hi! How can I help you?\"\n}\n```\"\"\",\n)\n\nprint(f\"parsed field before parsing: {dummy_response.parsed}\")\n\nparsed_response = parser.parse(dummy_response)\n\nprint(f\"parsed field after parsing: {parsed_response.parsed}\")\nprint(type(parsed_response.parsed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Error Handling\nIf the LLM output does not match the expected format, the parser will raise\nan error with a detailed message.\nSo developers can present the error message to LLM to guide it to correct\nthe output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "error_response = ModelResponse(\n    text=\"\"\"```json\n{\n    \"thought\": \"I should greet the user\"\n}\n```\"\"\",\n)\n\ntry:\n    parsed_response = parser.parse(error_response)\nexcept Exception as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Advanced Usage\nMore Complex Content\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAsking LLM to directly generate a JSON dictionary can be challenging,\nespecially when the JSON content is complex (e.g. code snippets, nested\nstructures).\nYou can utilize advanced parsers to structure the LLM output.\nHere is an example of a more complex parser that handle code snippets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.parsers import RegexTaggedContentParser\n\nparser = RegexTaggedContentParser(\n    format_instruction=\"\"\"Response in the following format:\n<thought>what you thought</thought>\n<number>A random number here</number>\n<code>your python code here</code>\n\"\"\",\n    try_parse_json=True,  # Try to parse each value as a JSON object\n    required_keys=[\n        \"thought\",\n        \"number\",\n        \"code\",\n    ],  # Required keys in the parsed dictionary\n)\n\nprint(parser.format_instruction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `RegexTaggedContentParser` uses regular expressions to match the tagged\ncontent in the text and return the parsed dictionary.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The parsed output of `RegexTaggedContentParser` is a dictionary, which means the required keys should be unique.</p></div>\nYou can also change the regular expression pattern by settings the `tagged_content_pattern` parameter when initializing the parser.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json\n\ndummy_response = ModelResponse(\n    text=\"\"\"<thought>Print the current date</thought>\n<number>42</number>\n<code>import datetime\nprint(datetime.datetime.now())\n</code>\n\"\"\",\n)\n\nparsed_response = parser.parse(dummy_response)\n\nprint(\"The type of parsed response: \", type(parsed_response.parsed))\nprint(\"The type of the number: \", type(parsed_response.parsed[\"number\"]))\nprint(json.dumps(parsed_response.parsed, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Auto Post-Processing\n\nWithin the parsed dictionary, different keys may require different\npost-processing steps.\nFor example, in a werewolf game, the LLM is playing the role of a seer, and\nthe output should contain the following keys:\n\n- `thought`: The seer's thoughts\n- `speak`: The seer's speech\n- `use_ability`: A boolean value indicating whether the seer should use its ability\n\nIn this case, the `thought` and `speak` contents should be stored in the\nagent's memory to ensure the consistency of the agent's behavior.\nThe `speak` content should be spoken out to the user.\nThe `use_ability` key should be accessed outside the agent easily to\ndetermine the game flow.\n\nAgentScope supports automatic post-processing of the parsed dictionary by\nproviding the following parameters when initializing the parser.\n\n- `keys_to_memory`: key(s) that should be stored in the agent's memory\n- `keys_to_content`: key(s) that should be spoken out\n- `keys_to_metadata`: key(s) that should be stored in the metadata field of the agent's response message\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If a string is provided, the parser will extract the value of the given key from the parsed dictionary. If a list of strings is provided, a sub-dictionary will be created with the given keys.</p></div>\n\nHere is an example of using the `MarkdownJsonDictParser` to automatically\npost-process the parsed dictionary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parser = MarkdownJsonDictParser(\n    content_hint='{\"thought\": \"what you thought\", \"speak\": \"what you speak\", \"use_ability\": \"whether to use the ability\"}',\n    keys_to_memory=[\"thought\", \"speak\"],\n    keys_to_content=\"speak\",\n    keys_to_metadata=\"use_ability\",\n)\n\ndummy_response = ModelResponse(\n    text=\"\"\"```json\n{\n    \"thought\": \"I should ...\",\n    \"speak\": \"I will not use my ability\",\n    \"use_ability\": false\n}```\n\"\"\",\n)\n\nparsed_response = parser.parse(dummy_response)\n\nprint(\"The parsed response: \", parsed_response.parsed)\nprint(\"To memory\", parser.to_memory(parsed_response.parsed))\nprint(\"To message content: \", parser.to_content(parsed_response.parsed))\nprint(\"To message metadata: \", parser.to_metadata(parsed_response.parsed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we show how to create an agent that can automatically post-process the\nparsed dictionary by the following core steps in the `reply` method.\n\n1. Put the format instruction in prompt to guide LLM to generate the desired output\n2. Parse the LLM response\n3. Post-process the parsed dictionary using relevant methods\n\n.. tip:: By changing different parsers, the agent can adapt to different scenarios and generate structured output in various formats.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from agentscope.models import DashScopeChatWrapper\nfrom agentscope.agents import AgentBase\nfrom agentscope.message import Msg\n\n\nclass Agent(AgentBase):\n    def __init__(self):\n        self.name = \"Alice\"\n        super().__init__(name=self.name)\n\n        self.sys_prompt = f\"You're a helpful assistant named {self.name}.\"\n\n        self.model = DashScopeChatWrapper(\n            config_name=\"_\",\n            model_name=\"qwen-max\",\n        )\n\n        self.parser = MarkdownJsonDictParser(\n            content_hint='{\"thought\": \"what you thought\", \"speak\": \"what you speak\", \"use_ability\": \"whether to use the ability\"}',\n            keys_to_memory=[\"thought\", \"speak\"],\n            keys_to_content=\"speak\",\n            keys_to_metadata=\"use_ability\",\n        )\n\n        self.memory.add(Msg(\"system\", self.sys_prompt, \"system\"))\n\n    def reply(self, msg):\n        self.memory.add(msg)\n\n        prompt = self.model.format(\n            self.memory.get_memory(),\n            # Instruct the model to respond in the required format\n            Msg(\"system\", self.parser.format_instruction, \"system\"),\n        )\n\n        response = self.model(prompt)\n\n        parsed_response = self.parser.parse(response)\n\n        self.memory.add(\n            Msg(\n                name=self.name,\n                content=self.parser.to_memory(parsed_response.parsed),\n                role=\"assistant\",\n            ),\n        )\n\n        return Msg(\n            name=self.name,\n            content=self.parser.to_content(parsed_response.parsed),\n            role=\"assistant\",\n            metadata=self.parser.to_metadata(parsed_response.parsed),\n        )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}